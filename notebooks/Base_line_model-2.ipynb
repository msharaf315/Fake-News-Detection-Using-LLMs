{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fxeDuc7eC3l"
   },
   "source": [
    "#Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "utquFM-8D-Bk"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mBaseLine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BiLSTMTextClassifierModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "# Create the baseline model\n",
    "class BiLSTMTextClassifierModel(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab, embedding_dim, hidden_dim, number_of_labels):\n",
    "    super(BiLSTMTextClassifierModel, self).__init__()\n",
    "    self.number_of_labels = number_of_labels\n",
    "    self.embedding = nn.Embedding(len(vocab), embedding_dim, vocab[\"<pad>\"])\n",
    "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "    self.top_layer = nn.Linear(2*hidden_dim, self.number_of_labels)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.softmax = F.softmax\n",
    "\n",
    "  def forward(self, x):\n",
    "    embeddings = self.embedding(x)\n",
    "    rnn_output, _ = self.rnn(embeddings)\n",
    "    last_hidden = rnn_output[:, -1, :]\n",
    "    top_layer_output = self.top_layer(self.relu(last_hidden))\n",
    "    return self.softmax(self.relu(top_layer_output), dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qECjKYDhYw2M"
   },
   "outputs": [],
   "source": [
    "# trains one batch, returns total batch loss\n",
    "def train_one_batch(model, inputs, targets, optimizer, loss_function):\n",
    "        # Predict/Forward Pass\n",
    "        predictions = model(inputs)\n",
    "        # Compute loss\n",
    "        loss = loss_function(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Multiply the cross entropy loss which is the average by the batch size so we get the total loss for the batch, we can divide this by all data set \n",
    "        # Size to get average loss for the epoch\n",
    "        batch_size_train =  len(inputs)\n",
    "        batch_loss = loss.item() * batch_size_train\n",
    "        return batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validates one batch, returns total batch loss, number of true positives\n",
    "def validate_one_batch(model, inputs, targets, loss_function):\n",
    "        predictions_val = model(inputs).detach()\n",
    "        loss_validation = loss_function(predictions_val, targets)\n",
    "        \n",
    "        \n",
    "        # calculate average loss\n",
    "        batch_size_val = len(inputs)\n",
    "        batch_loss = loss_validation.item() * batch_size_val\n",
    "        \n",
    "        # Calculate True positives\n",
    "        predicted_class = predictions_val.argmax(axis=1)\n",
    "        correct_class = targets.argmax(axis=1)\n",
    "    \n",
    "        true_positives_count = sum(predicted_class == correct_class).item()\n",
    "        return batch_loss, true_positives_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Af0qNvDngmFW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, average train loss: 1.7836974520236253, average val loss: 1.7813379786838994, val accuracy: 0.21573208722741433,  training time : 2.9156482219696045\n",
      "epoch 2, average train loss: 1.7834785602986813, average val loss: 1.789648190094303, val accuracy: 0.19470404984423675,  training time : 2.095219373703003\n",
      "epoch 3, average train loss: 1.7815971709787846, average val loss: 1.7851098293084593, val accuracy: 0.205607476635514,  training time : 1.9737038612365723\n",
      "epoch 4, average train loss: 1.7747184906154871, average val loss: 1.7953519204695276, val accuracy: 0.220404984423676,  training time : 1.861588716506958\n",
      "epoch 5, average train loss: 1.7767615742981433, average val loss: 1.7919336234297707, val accuracy: 0.1923676012461059,  training time : 2.1257686614990234\n",
      "epoch 6, average train loss: 1.762551800906658, average val loss: 1.785548113588232, val accuracy: 0.21261682242990654,  training time : 2.2622108459472656\n",
      "epoch 7, average train loss: 1.7333800189197064, average val loss: 1.783383581497216, val accuracy: 0.21105919003115264,  training time : 1.7445361614227295\n",
      "epoch 8, average train loss: 1.7198796544224024, average val loss: 1.7822311258761683, val accuracy: 0.2118380062305296,  training time : 1.970538854598999\n",
      "epoch 9, average train loss: 1.7120184708386659, average val loss: 1.7896801853477027, val accuracy: 0.220404984423676,  training time : 1.9988033771514893\n",
      "epoch 10, average train loss: 1.6952148728072642, average val loss: 1.7939530079981247, val accuracy: 0.22274143302180685,  training time : 2.8695576190948486\n",
      "epoch 11, average train loss: 1.6726447761058807, average val loss: 1.8042985965901075, val accuracy: 0.19003115264797507,  training time : 2.3767709732055664\n",
      "epoch 12, average train loss: 1.650312877073884, average val loss: 1.8068197349150232, val accuracy: 0.1939252336448598,  training time : 2.0734121799468994\n",
      "epoch 13, average train loss: 1.6275198075920343, average val loss: 1.806782593608274, val accuracy: 0.1939252336448598,  training time : 1.534726858139038\n",
      "epoch 14, average train loss: 1.6136712346225976, average val loss: 1.806359382433312, val accuracy: 0.18925233644859812,  training time : 1.5026435852050781\n",
      "epoch 15, average train loss: 1.6011383555829526, average val loss: 1.8127681807936908, val accuracy: 0.19314641744548286,  training time : 1.513542890548706\n",
      "epoch 16, average train loss: 1.591320164501667, average val loss: 1.8033176627114555, val accuracy: 0.1853582554517134,  training time : 1.8337109088897705\n",
      "epoch 17, average train loss: 1.5811531566083432, average val loss: 1.804421475371839, val accuracy: 0.18769470404984423,  training time : 2.6661765575408936\n",
      "epoch 18, average train loss: 1.5738161761313676, average val loss: 1.8142449291324318, val accuracy: 0.17523364485981308,  training time : 1.7475385665893555\n",
      "epoch 19, average train loss: 1.5612924844026566, average val loss: 1.8125059805183767, val accuracy: 0.17990654205607476,  training time : 1.7925500869750977\n",
      "epoch 20, average train loss: 1.5575634501874447, average val loss: 1.8101420201987863, val accuracy: 0.1838006230529595,  training time : 1.5985918045043945\n",
      "epoch 21, average train loss: 1.5502046450972558, average val loss: 1.8052640258337478, val accuracy: 0.18146417445482865,  training time : 1.8039588928222656\n",
      "epoch 22, average train loss: 1.5430880170315504, average val loss: 1.8086511290333354, val accuracy: 0.1806853582554517,  training time : 1.660642385482788\n",
      "epoch 23, average train loss: 1.5417344480752946, average val loss: 1.8118518880594556, val accuracy: 0.17445482866043613,  training time : 1.5666418075561523\n",
      "epoch 24, average train loss: 1.5398396078497172, average val loss: 1.8138889828203624, val accuracy: 0.17289719626168223,  training time : 1.875861644744873\n",
      "epoch 25, average train loss: 1.5372732620686294, average val loss: 1.8113010070777014, val accuracy: 0.17133956386292834,  training time : 1.4383385181427002\n",
      "epoch 26, average train loss: 1.5345146082341672, average val loss: 1.8133838496104209, val accuracy: 0.17601246105919002,  training time : 1.77656888961792\n",
      "epoch 27, average train loss: 1.5318866170942784, average val loss: 1.8122187091554065, val accuracy: 0.1674454828660436,  training time : 2.682959794998169\n",
      "epoch 28, average train loss: 1.5256092593073844, average val loss: 1.8123047344409788, val accuracy: 0.1658878504672897,  training time : 2.629415512084961\n",
      "epoch 29, average train loss: 1.52357855476439, average val loss: 1.8141002714448258, val accuracy: 0.1674454828660436,  training time : 2.0223922729492188\n",
      "epoch 30, average train loss: 1.5168928731232882, average val loss: 1.8083299528401218, val accuracy: 0.16978193146417445,  training time : 3.2560510635375977\n",
      "epoch 31, average train loss: 1.516263635829091, average val loss: 1.811348735357742, val accuracy: 0.1674454828660436,  training time : 2.796536445617676\n",
      "epoch 32, average train loss: 1.5133220169693231, average val loss: 1.802393560468965, val accuracy: 0.17289719626168223,  training time : 2.459878444671631\n",
      "epoch 33, average train loss: 1.5107690539211034, average val loss: 1.8099191946404003, val accuracy: 0.1588785046728972,  training time : 2.4607694149017334\n",
      "epoch 34, average train loss: 1.5103980414569378, average val loss: 1.813211091953646, val accuracy: 0.16277258566978192,  training time : 1.9548640251159668\n",
      "epoch 35, average train loss: 1.5089611124247313, average val loss: 1.8073996064076172, val accuracy: 0.1705607476635514,  training time : 1.5970332622528076\n",
      "epoch 36, average train loss: 1.5074836786836385, average val loss: 1.8104622750267434, val accuracy: 0.16666666666666666,  training time : 1.600654125213623\n",
      "epoch 37, average train loss: 1.5081117205321788, average val loss: 1.7986956905353106, val accuracy: 0.16666666666666666,  training time : 1.6038718223571777\n",
      "epoch 38, average train loss: 1.5060303591191768, average val loss: 1.8005002105718833, val accuracy: 0.1588785046728972,  training time : 1.5954725742340088\n",
      "epoch 39, average train loss: 1.5095489561557769, average val loss: 1.806255939964936, val accuracy: 0.15654205607476634,  training time : 2.1023998260498047\n",
      "epoch 40, average train loss: 1.504592676833272, average val loss: 1.8052860795523147, val accuracy: 0.16510903426791276,  training time : 2.1902811527252197\n",
      "epoch 41, average train loss: 1.5017394434660674, average val loss: 1.8119110348068665, val accuracy: 0.15654205607476634,  training time : 2.375734329223633\n",
      "epoch 42, average train loss: 1.5005548540502787, average val loss: 1.801446746814288, val accuracy: 0.15342679127725856,  training time : 2.588308811187744\n",
      "epoch 43, average train loss: 1.4984779119491578, average val loss: 1.8054332621743745, val accuracy: 0.16355140186915887,  training time : 2.881845235824585\n",
      "epoch 44, average train loss: 1.50011434443295, average val loss: 1.8024848443325434, val accuracy: 0.16822429906542055,  training time : 2.120626449584961\n",
      "epoch 45, average train loss: 1.5009448301047086, average val loss: 1.805146282707048, val accuracy: 0.16199376947040497,  training time : 2.2838985919952393\n",
      "epoch 46, average train loss: 1.497611588984728, average val loss: 1.8027583594634153, val accuracy: 0.1573208722741433,  training time : 2.1963319778442383\n",
      "epoch 47, average train loss: 1.4965124517679214, average val loss: 1.8112794521070343, val accuracy: 0.16199376947040497,  training time : 1.9344134330749512\n",
      "epoch 48, average train loss: 1.4942616827785968, average val loss: 1.808003242884841, val accuracy: 0.15965732087227413,  training time : 1.5397045612335205\n",
      "epoch 49, average train loss: 1.498847357928753, average val loss: 1.8052169853281752, val accuracy: 0.16277258566978192,  training time : 1.4968359470367432\n",
      "epoch 50, average train loss: 1.4970450125634671, average val loss: 1.8070317139135343, val accuracy: 0.1573208722741433,  training time : 2.070423126220703\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = BiLSTMTextClassifierModel(liar_vocab, 300, 128, 6)\n",
    "# Training params\n",
    "num_epochs = 50\n",
    "# Hyper parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:6\")\n",
    "model.to(device)\n",
    "loss_fn.to(device)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "val_accuracy_history = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0. \n",
    "    total_data_points_train = 0\n",
    "    for train_batch in train_loader:\n",
    "        inputs = train_batch[0].to(device)\n",
    "        targets = train_batch[1].to(device)\n",
    "        \n",
    "        train_batch_loss = train_one_batch(model, inputs, targets, optimizer, loss_fn)\n",
    "        \n",
    "        total_train_loss += train_batch_loss\n",
    "        total_data_points_train += len(inputs)\n",
    "    \n",
    "    \n",
    "    average_epoch_loss_train = total_train_loss/total_data_points_train\n",
    "    train_loss.append(average_epoch_loss_train)\n",
    "    \n",
    "    # Validation\n",
    "    # TODO restructure\n",
    "    model.eval()        \n",
    "    total_val_loss = 0. \n",
    "    total_data_points_val = 0\n",
    "    true_positives_val = 0\n",
    "    for validation_batch in validation_loader:\n",
    "        inputs_val = validation_batch[0].to(device)\n",
    "        targets_val = validation_batch[1].to(device)\n",
    "        \n",
    "        # Returns loss and true positives count\n",
    "        batch_loss_val, true_positives_count = validate_one_batch(model, inputs_val, targets_val, loss_fn)\n",
    "            \n",
    "        # calculate average loss and appends true positives count\n",
    "        total_val_loss += batch_loss_val\n",
    "        total_data_points_val += len(inputs_val)\n",
    "        true_positives_val += true_positives_count\n",
    "    \n",
    "    average_epoch_loss_val = total_val_loss/total_data_points_val\n",
    "    val_accuracy = true_positives_val/total_data_points_val\n",
    "    val_accuracy_history.append(val_accuracy)    \n",
    "    val_loss.append(average_epoch_loss_val)\n",
    "    \n",
    "        \n",
    "    # Print every epoch's metrics\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"epoch {epoch + 1}, average train loss: {average_epoch_loss_train}, average val loss: {average_epoch_loss_val}, val accuracy: {val_accuracy},  training time : {elapsed_time}\")\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test loss: 1.8184774796983438, accuracy: 0.1499605367008682\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()        \n",
    "total_test_loss = 0. \n",
    "total_data_points_test = 0\n",
    "true_positives_test = 0\n",
    "i=0\n",
    "for test_batch in test_loader:\n",
    "    inputs_test = test_batch[0].to(device)\n",
    "    targets_test = test_batch[1].to(device)\n",
    "    # Returns loss and true positives count\n",
    "    batch_loss_test, true_positives_count = validate_one_batch(model, inputs_test, targets_test, loss_fn)\n",
    "            \n",
    "    # calculate average loss and appends true positives count\n",
    "    total_test_loss += batch_loss_test\n",
    "    total_data_points_test += len(inputs_test)\n",
    "    true_positives_test += true_positives_count\n",
    "    \n",
    "average_epoch_loss_test = total_test_loss/total_data_points_test\n",
    "accuracy_test = true_positives_test/total_data_points_test\n",
    "print(f\"average test loss: {average_epoch_loss_test}, accuracy: {accuracy_test}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
